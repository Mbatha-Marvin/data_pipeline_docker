version: '3.7'

services:
  # namenode:
  #   image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
  #   container_name: namenode
  #   restart: always
  #   ports:
  #     - "9870:9870"
  #     - "8020:8020"
  #   environment:
  #     - CLUSTER_NAME=test
  #   env_file:
  #     - ./hadoop/hadoop.env
  #   volumes:
  #     - hadoop_namenode:/hadoop/dfs/name


  # datanode:
  #   image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
  #   container_name: datanode
  #   restart: always
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:9870"
  #   env_file:
  #     - ./hadoop/hadoop.env
  #   volumes:
  #     - hadoop_datanode:/hadoop/dfs/data


  # spark-master:
  #   image: bde2020/spark-master:3.1.1-hadoop3.2
  #   container_name: spark-master
  #   ports:
  #     - "7077:7077"
  #     - "4040:4040"
  #   environment:
  #     - INIT_DAEMON_STEP=setup_spark
  #     - SPARK_MASTER_WEBUI_PORT=4040


  # spark-worker-1:
  #   image: bde2020/spark-worker:3.1.1-hadoop3.2
  #   container_name: spark-worker-1
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8091:4041"
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"


  # spark-worker-2:
  #   image: bde2020/spark-worker:3.1.1-hadoop3.2
  #   container_name: spark-worker-2
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8092:4042"
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"


  postgres:
    image: postgres:15
    # container_name: airflow_postgres_database
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/airflow_postgresql/data
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "airflow" ]
      interval: 5s
      retries: 5


  # metabase_postgres:
  #   image: postgres:15
  #   container_name: metabase_postgres
  #   restart: always
  #   environment:
  #     POSTGRES_USER: metabase
  #     POSTGRES_PASSWORD: 5713
  #     POSTGRES_DB: metabase
  #   volumes:
  #     - db_metabase_data:/var/lib/metabase_postgresql/data
  #   ports:
  #     - 5433:5433

  processed_postgres:
    image: postgres:15
    container_name: processed_postgres
    hostname: processed_postgres
    restart: always
    environment:
      POSTGRES_USER: metabase_processed
      POSTGRES_PASSWORD: 5713
      POSTGRES_DB: metabase_processed
    volumes:
      - db_processed_data:/var/lib/processed_postgresql/data
    ports:
      - 5434:5434
    deploy:
      mode: global

  # adminer:
  #   image: adminer
  #   container_name: Adminer
  #   restart: always
  #   ports:
  #     - '8090:8080'
  #   depends_on:
  #     - 'processed_postgres'
  

  # dataviz:
  #   image: metabase/metabase
  #   container_name: metabase_data_viz
  #   restart: always
  #   environment:
  #     MB_DB_TYPE: postgres
  #     MB_DB_DBNAME: metabase
  #     MB_DB_PORT: 5432
  #     MB_DB_USER: metabase
  #     MB_DB_PASS: 5713
  #     MB_DB_HOST: metabase_postgres
  #     MB_DB_FILE: /metabase-data/metabase.db
  #     JAVA_TIMEZONE: Africa/Nairobi
  #   depends_on:
  #     - metabase_postgres
  #   volumes:
  #     - dataviz_data:/metabase-data
  #   ports:
  #     - 3000:3000

  webserver:
    build: .
    container_name: airflow_webserver
    restart: always
    depends_on:
      - postgres
      - processed_postgres
    environment:
      - FERNET_KEY=${FERNET_KEY}
    logging:
      options:
        max-size: 10m
        max-file: "3"
    volumes:
      - ../airflow/dags:/opt/airflow/dags
      - ../airflow/data:/opt/airflow/data
      - ../airflow/logs:/opt/airflow/logs
      - ../airflow/plugins:/opt/airflow/plugins
      - ../spark:/usr/local/spark/app
      - /home/mbatha-marvin/Desktop/Spark/Vehicle_Data_Analysis/vehicles/data:/opt/airflow/bigData
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: [ "CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]" ]
      interval: 30s
      timeout: 30s
      retries: 3

  
  superset:
   image: apache/superset:latest
   container_name: superset
   restart: always
   depends_on:
      - postgres
      - processed_postgres
   volumes:
     - superset_app:/app
     - superset_home:/app/superset
     - superset_frontend:/app/superset/superset-frontend

   ports:
      - "8088:8088"


      

volumes:
  postgres-db-volume:
  # db_metabase_data:
  # dataviz_data:
  db_processed_data:
  # hadoop_namenode:
  # hadoop_datanode:
  superset_app:
  superset_home: 
  superset_frontend:
